{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "KHr1bUcyzcCO"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade \\\n",
        "  gradio \\\n",
        "  googlesearch-python \\\n",
        "  beautifulsoup4 \\\n",
        "  requests \\\n",
        "  llama-cpp-python \\\n",
        "  transformers \\\n",
        "  rapidfuzz \\\n",
        "  spacy[transformers]\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googlesearch import search\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "from rapidfuzz import process\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Pre-load summarizer\n",
        "summarizer_pipeline = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "# A simple list of known company names for fuzzy matching\n",
        "KNOWN_COMPANIES = [\"Google\", \"Apple\", \"Microsoft\", \"Amazon\", \"Meta\", \"Tesla\", \"Netflix\", \"Samsung\", \"Intel\", \"Nvidia\", \"IBM\", \"Adobe\", \"Twitter\"]\n",
        "\n",
        "# --- Agent Classes ---\n",
        "\n",
        "class SearchAgent:\n",
        "    def get_links(self, company, num_results=3):\n",
        "        query = f\"{company} latest news\"\n",
        "        return list(search(query, num_results=num_results))\n",
        "\n",
        "class ScrapeAgent:\n",
        "    def get_article_text(self, url):\n",
        "        try:\n",
        "            res = requests.get(url, timeout=5)\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "            text = ' '.join(p.get_text() for p in soup.find_all('p'))\n",
        "            return text[:3000]\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "class SummarizerAgent:\n",
        "    def summarize(self, text, style=\"formal\"):\n",
        "      if not text.strip():\n",
        "          return \"No content found to summarize.\"\n",
        "\n",
        "      input_len = len(text.split())\n",
        "      max_len = max(20, min(130, int(input_len * 0.6)))  # 60% of input\n",
        "      min_len = max(10, int(max_len * 0.5))              # half of max_len\n",
        "\n",
        "      try:\n",
        "          summary = summarizer_pipeline(\n",
        "              text,\n",
        "              max_length=max_len,\n",
        "              min_length=min_len,\n",
        "              do_sample=False\n",
        "          )[0]['summary_text']\n",
        "      except Exception as e:\n",
        "          return f\"Error during summarization: {e}\"\n",
        "\n",
        "      if style == \"casual\":\n",
        "          return f\"Hereâ€™s the gist: {summary}\"\n",
        "      elif style == \"bullets\":\n",
        "          return \"â€¢ \" + summary.replace('. ', '.\\nâ€¢ ')\n",
        "      else:\n",
        "          return summary\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_trf\")  # Open-source, free\n",
        "\n",
        "class ChatAgent:\n",
        "\n",
        "    GENERIC_WORDS = {\"news\", \"latest\", \"company\", \"update\", \"updates\", \"report\", \"headline\", \"business\"}\n",
        "\n",
        "    def is_company_question(self, user_input):\n",
        "      keywords = [\"news\", \"latest\", \"about\", \"update\", \"tell\", \"report\", \"new\"]\n",
        "      return any(word in user_input.lower() for word in keywords)\n",
        "\n",
        "\n",
        "    def extract_companies(self, user_input):\n",
        "        doc = nlp(user_input)\n",
        "        candidates = set()\n",
        "\n",
        "        # 1. Extract ORG-type entities (like Google, Meta)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"ORG\":\n",
        "                candidates.add(ent.text.strip())\n",
        "\n",
        "        # 2. Match against known companies (fuzzy matching)\n",
        "        final_matches = set()\n",
        "        for name in candidates:\n",
        "            result = process.extractOne(name, KNOWN_COMPANIES)\n",
        "            if result and result[1] > 85:\n",
        "                final_matches.add(result[0])\n",
        "            else:\n",
        "                final_matches.add(name)  # Accept unknown name as potential company\n",
        "\n",
        "        return list(final_matches)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q78d98yC1CTl",
        "outputId": "e171f3d2-2634-4122-f1e5-fb65a1fcbfca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize agents\n",
        "search_agent = SearchAgent()\n",
        "scrape_agent = ScrapeAgent()\n",
        "summarizer_agent = SummarizerAgent()\n",
        "chat_agent = ChatAgent()\n",
        "\n",
        "\n",
        "def handle_chat(user_input, style=\"formal\"):\n",
        "    greetings = [\"hi\", \"hello\", \"hey\", \"how are you\"]\n",
        "    if user_input.lower().strip() in greetings:\n",
        "        return \"Hi! ðŸ‘‹ I'm your news buddy. Ask me about any company!\"\n",
        "\n",
        "    if not chat_agent.is_company_question(user_input):\n",
        "        return \"I'm a bot to get only company latest news. Sorry, I could not answer these questions.\"\n",
        "\n",
        "    companies = chat_agent.extract_companies(user_input)\n",
        "    if not companies:\n",
        "        return \"Sorry, I couldn't recognize any valid company in your message. Try again with correct names.\"\n",
        "\n",
        "    full_response = \"\"\n",
        "    for company in companies:\n",
        "        links = search_agent.get_links(company)\n",
        "        if not links:\n",
        "            full_response += f\"ðŸ”¹ **{company}**\\nNo news links found.\\n\\n\"\n",
        "            continue\n",
        "\n",
        "        summaries = []\n",
        "        additional_links = []\n",
        "        for link in links:\n",
        "            article = scrape_agent.get_article_text(link)\n",
        "            summary = summarizer_agent.summarize(article, style)\n",
        "\n",
        "            # If summary is valid, add it under the company section\n",
        "            if \"No content\" in summary or \"Error during summarization\" in summary:\n",
        "                additional_links.append(link)\n",
        "            else:\n",
        "                summaries.append(f\"â€¢ {summary}\\n[Read full article]({link})\")\n",
        "\n",
        "        # Add the summaries (if any)\n",
        "        if summaries:\n",
        "            full_response += f\"ðŸ”¹ **{company}**\\n\" + \"\\n\\n\".join(summaries) + \"\\n\\n\"\n",
        "\n",
        "        # Add \"Additional links\" section (if any)\n",
        "        if additional_links:\n",
        "            full_response += f\"ðŸ“Ž **Additional links for {company}:**\\n\" + \\\n",
        "                            \"\\n\".join(f\"[Open]({link})\" for link in additional_links) + \"\\n\\n\"\n",
        "\n",
        "\n",
        "\n",
        "    return full_response.strip() or \"No content could be fetched at the moment.\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4PCN3gVK5wcA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "style_choices = [\"formal\", \"casual\", \"bullets\"]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=handle_chat,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ask about a company or just chat\"),\n",
        "        gr.Dropdown(choices=style_choices, label=\"Output Style\", value=\"formal\")\n",
        "    ],\n",
        "    outputs=\"markdown\",\n",
        "    title=\"ðŸ“° Smart Company News Bot\",\n",
        "    description=\"Ask about companies like Google, Meta, Apple. Get real-time news summaries in your selected style!\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "lv2T5Zj_58B3",
        "outputId": "610348b5-3882-492f-e155-be1a3e967760"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f2b12c61c587cd9d63.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f2b12c61c587cd9d63.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f2b12c61c587cd9d63.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}