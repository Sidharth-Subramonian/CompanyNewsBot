# -*- coding: utf-8 -*-
"""KnowCompany.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-FMEugLUu2AmunnanZxshFVNUG0zZY5e
"""

!pip install -q --upgrade \
  gradio \
  googlesearch-python \
  beautifulsoup4 \
  requests \
  llama-cpp-python \
  transformers \
  rapidfuzz \
  spacy[transformers]

from googlesearch import search
import requests
from bs4 import BeautifulSoup
from transformers import pipeline
from rapidfuzz import process
import re
import spacy


# Pre-load summarizer
summarizer_pipeline = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

# A simple list of known company names for fuzzy matching
KNOWN_COMPANIES = ["Google", "Apple", "Microsoft", "Amazon", "Meta", "Tesla", "Netflix", "Samsung", "Intel", "Nvidia", "IBM", "Adobe", "Twitter"]

# --- Agent Classes ---

class SearchAgent:
    def get_links(self, company, num_results=3):
        query = f"{company} latest news"
        return list(search(query, num_results=num_results))

class ScrapeAgent:
    def get_article_text(self, url):
        try:
            res = requests.get(url, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            text = ' '.join(p.get_text() for p in soup.find_all('p'))
            return text[:3000]
        except:
            return ""

class SummarizerAgent:
    def summarize(self, text, style="formal"):
      if not text.strip():
          return "No content found to summarize."

      input_len = len(text.split())
      max_len = max(20, min(130, int(input_len * 0.6)))  # 60% of input
      min_len = max(10, int(max_len * 0.5))              # half of max_len

      try:
          summary = summarizer_pipeline(
              text,
              max_length=max_len,
              min_length=min_len,
              do_sample=False
          )[0]['summary_text']
      except Exception as e:
          return f"Error during summarization: {e}"

      if style == "casual":
          return f"Hereâ€™s the gist: {summary}"
      elif style == "bullets":
          return "â€¢ " + summary.replace('. ', '.\nâ€¢ ')
      else:
          return summary

nlp = spacy.load("en_core_web_trf")  # Open-source, free

class ChatAgent:

    GENERIC_WORDS = {"news", "latest", "company", "update", "updates", "report", "headline", "business"}

    def is_company_question(self, user_input):
      keywords = ["news", "latest", "about", "update", "tell", "report", "new"]
      return any(word in user_input.lower() for word in keywords)


    def extract_companies(self, user_input):
        doc = nlp(user_input)
        candidates = set()

        # 1. Extract ORG-type entities (like Google, Meta)
        for ent in doc.ents:
            if ent.label_ == "ORG":
                candidates.add(ent.text.strip())

        # 2. Match against known companies (fuzzy matching)
        final_matches = set()
        for name in candidates:
            result = process.extractOne(name, KNOWN_COMPANIES)
            if result and result[1] > 85:
                final_matches.add(result[0])
            else:
                final_matches.add(name)  # Accept unknown name as potential company

        return list(final_matches)

# Initialize agents
search_agent = SearchAgent()
scrape_agent = ScrapeAgent()
summarizer_agent = SummarizerAgent()
chat_agent = ChatAgent()


def handle_chat(user_input, style="formal"):
    greetings = ["hi", "hello", "hey", "how are you"]
    if user_input.lower().strip() in greetings:
        return "Hi! ðŸ‘‹ I'm your news buddy. Ask me about any company!"

    if not chat_agent.is_company_question(user_input):
        return "I'm a bot to get only company latest news. Sorry, I could not answer these questions."

    companies = chat_agent.extract_companies(user_input)
    if not companies:
        return "Sorry, I couldn't recognize any valid company in your message. Try again with correct names."

    full_response = ""
    for company in companies:
        links = search_agent.get_links(company)
        if not links:
            full_response += f"ðŸ”¹ **{company}**\nNo news links found.\n\n"
            continue

        summaries = []
        additional_links = []
        for link in links:
            article = scrape_agent.get_article_text(link)
            summary = summarizer_agent.summarize(article, style)

            # If summary is valid, add it under the company section
            if "No content" in summary or "Error during summarization" in summary:
                additional_links.append(link)
            else:
                summaries.append(f"â€¢ {summary}\n[Read full article]({link})")

        # Add the summaries (if any)
        if summaries:
            full_response += f"ðŸ”¹ **{company}**\n" + "\n\n".join(summaries) + "\n\n"

        # Add "Additional links" section (if any)
        if additional_links:
            full_response += f"ðŸ“Ž **Additional links for {company}:**\n" + \
                            "\n".join(f"[Open]({link})" for link in additional_links) + "\n\n"



    return full_response.strip() or "No content could be fetched at the moment."

import gradio as gr

style_choices = ["formal", "casual", "bullets"]

gr.Interface(
    fn=handle_chat,
    inputs=[
        gr.Textbox(label="Ask about a company or just chat"),
        gr.Dropdown(choices=style_choices, label="Output Style", value="formal")
    ],
    outputs="markdown",
    title="ðŸ“° Smart Company News Bot",
    description="Ask about companies like Google, Meta, Apple. Get real-time news summaries in your selected style!"
).launch(debug=True)